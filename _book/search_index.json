[
["future.html", "Chapter 5 Oportunities for advancing field 5.1 What to do with all those parameters 5.2 Inference 5.3 Small or sparse data", " Chapter 5 Oportunities for advancing field While up to now has been an overview of the techniques that have been successfully and commonly implemented in sequential classification problems, this chapter will be devoted to new efforts to solving problems associated with the aforementioned methods. In addition to being a survey of the current state of the art it will also identify potential avenues for new research that could enhance our ability to work with sequential data subjected to various constraints. 5.1 What to do with all those parameters A large issue with not just sequence-based deep learning, but the field as a whole is how large models are. For instance: VGGnet (Simonyan and Zisserman (2014)), the second place winner of the 2014 ImageNet competition and an extremely common model to use for image recognition tasks has 138 million parameters to tune. Going by the rule of thumb from Frank Harrell book “Regression Modeling Strategies”(Harrell Jr (2015)) of 10-20 observations per parameter in our model this is an issue, especially given the size of the data-set that the VGGnet model was trained on was only one million images. Even simple models have large amounts of parameters to tune. A model with just a single hidden layer taking a ten dimensional input and a hidden layer of ten neurons performing binary classification would have (with bias parameters included) \\((10*11) + (10*11) + (2*11) = 242\\) parameters to tune. 5.1.1 Theory backed methods for choosing model architectures How then, did the VGGnet model achieve an accuracy of 93% on the test set? The answer lies in the fact that data is not shared over parameters in the same way it is in regression models. This stems from the fact that each layer’s parameters are using as their input the output from the previous layer, and thus are reusing data in some sense. While it does not appear that this means we only need to count the parameters in the first layer, it does mean that deep learning models need to be thought of differently than traditional regression based models in terms of parameter complexity. As of yet, no solid theoretical explanation of exactly what is happening with the data to parameter learning in deep neural networks, and thus there are no concrete guidelines to model construction. Difficulties in ascertaining these guidelines seems in part due to the non-convex optimization routines used for the models. The combination of the lack of theory and the computational time needed to train deep neural networks all but ruling out more traditional grid-search techniques for tuning layer numbers/size imply that there exists the potential for very impact research in this area. 5.1.2 Runtime on mobile hardware hardware Another impact of having extremely large models is they take a long time to not only train, but to be used to predict as well. If deep learning models are to be brought to mobile devices such as smart phones or watches the models need to be scaled down in terms of their size and run time complexity substantially. Efforts towards this have been successful with models such as SqueezeNet (Iandola et al. (2016)) drastically reducing the number of parameters while still maintaining a good level of accuracy in ImageNet prediction performance. In addition, certain forms of penalization such as \\(L_0\\) penalization can be applied to ‘thin out’ a network by forcing certain weights to drop to zero and then throwing them out (Louizos, Welling, and Kingma (2017)), all while performing a single run of stochastic gradient descent, eliminating the need to do costly re-training of the network after dropping weights. Great opportunity lies the development of objective and rigorous methods of eliminating unnecessary parameters in models. Approaches such as regularization are promising as are the evaluation of the models response to techniques such as ‘dropout’ where by neurons are randomly dropped during training in an effort to build robust prediction pathways. An analysis of the models robustness to certain neuron’s being dropped may indicate the potential for sparsity inducing techniques. 5.2 Inference A great source of confusion for many statisticians when reading literature in the deep learning world is that in many cases the same words have different meanings. “Inference” is a good example of this. To a statistician inference means the dissection of the inner workings of the model: what parameters are used to make predictions and how confident are we in those parameters. In deep learning, inference simply refers to the use of a model for prediction. There are a few things that stand in the way of traditional inference in deep learning models. 5.2.1 Peering into the black box Often it is common to hear people refer to deep neural networks as “black box predictors.” This meaning simply that data goes in and the model performs some uninterpreted transformations to that data and returns its prediction. While in giant models such as VGGnet this may be the case, it is actually quite possible to see what is going on within a neural network, just the quantity of information to understand is too high to fully comprehend it in its raw form. I believe that the desire for traditional inference in the statistical sense is a limiting goal. Having a parameter estimate and its uncertainty works well when models are single-stage linear combinations of the data, but neural networks, and arguably the world, does not work like that. Traditional inference has relied on making (hopefully) non-impactful simplifications on the true nature of the system being modeled in order for it to fit the framework of linear models. With deep learning we have a model theoretically capable of modeling any function of data and I think we should take advantage of that. If the model objectively performs well, we should perform the simplification on the explanation side, rather than the model side. How exactly this is done is not a solved issue (and may never be), but some early examples include the work of visualizing the constitutional layers in computer vision models (Olah, Mordvintsev, and Schubert (2017)): investigating the features learned by neural networks can provide insight into the problem greatly. 5.2.2 Generative Adversarial Networks One approach to simultaneously attempting to train a better model, but also understand the workings of a model is a class of deep learning models called “generative adversarial networks” (or GANs)(Goodfellow et al. (2014)). GANs train two separate networks in tandem: a generator and a discriminator. The job is for the generator to construct fake examples of some training set and the discriminator’s job is to decide if the example is a real observation or a generated one. These models have shown remarkable results in terms of image generation such as those recently presented by NVIDIA 5.1 (Karras et al. (2017)). Figure 5.1: The output of a generative adversarial network trained on a database of celebrity faces. Both faces seen are entirely generated by the model and show that it learned to a very precise degree, what constitutes a ‘face.’ One potentially valuable for inference property of sample generated by GANs is they show what the model is ‘seeing’ when it chooses to classify something as a given class. For instance, an over-fit model may classify a house as a house because it sees a lot of the color blue in the sky. If that was the case a GAN would simply return a blue canvas when asked to generate a house. Recently, a team at ETH Zurich used GANs on time series data taken from hospital records (Esteban, Hyland, and Rätsch (2017)) and found that GANs could be used successfully on these data to generate realistic looking medical data, suggesting that the model was learning underlying patterns well1. 5.2.3 Causality problems While much of deep learning is not currently focused on uncovering causal pathways, given the ability of these models to generalize so well, it is worth exploring the issue more. One area of concern with the models mentioned is the temporarily of data. For instance, in constitutional methods for sequence classification, often the convolutions are allowed to explore not only back in time, but also forward in time to classify at a given instance. The same goes with a class of RNNs that we didn’t discuss but have proved successful: the bi-directional RNN. In this case the RNN’s hidden state path travels not only forward in time, but also backwards. These models that can see both backward and forward in time often perform better than their omni-directional counterparts. For instance, in speech the “au” phoneme may indicate an ‘e’ or an ‘a’ in a word, but it only becomes clear after the end of the word is heard which value it is. However, the flow of causality is forward in time, so these models explicitly violate this. Potentially fitting a model that has the ability to see both forward and reverse temporal dependencies and then investigating the dependencies that were discovered by both directions could provide some insight into this. For instance, if the backwards in time component of the RNN found that the administration of some drug was a strong signal that high blood-pressure would later occur, but not the reverse direction the relationship could warrant further experimental exploration of causality potential. It would be necessary to make sure that the patterns discovered were not due to residuals from the reverse-time predictors, but this could be done by forcing the model to ‘forget’ those patterns and seeing if our forward-time trends remain. 5.3 Small or sparse data Deep learning has come to be almost synonymous with ‘big data.’ Most of the groundbreaking work tends to come out of large companies with massive data-sets and near-infinite compute power to fit their models. This has left the area of deep learning corresponding to small data relatively unexplored. We have already seen that deep learning models seem to use their parameters more efficiently than traditional statistical methods, but that is clearly not without limit. The following are brief survey of a few techniques for dealing with small or sparse (meaning a large portion missing labels) data. 5.3.1 Bayesian deep learning As we have seen, a neural network is essentially a series of stacked linear models with static non-linear transformations applied. Much like we can fit a regression model in a Bayesian context, we can fit a deep neural network with Bayesian techniques. To do so, each tuneable parameter is simply provided a prior (usually a normal centered at zero) and the posterior model is determined the same as any other Bayesian model. Usually variational inference techniques are used instead of sampling techniques such as Hamiltonian Monte Carlo due to the size of the models (Blundell et al. (2015)). Bayesian neural networks have been shown to perform more efficiently on small data-sets than traditional models (Srivastava et al. (2014)). In addition, some generative models such as autoencoders (see section below) have shown subjectively better results from Bayesian implementations than standard implementations (Kingma and Welling (2013)). 5.3.2 Semi-supervised methods In many circumstances the data may not be small as a whole, but the number of observations that have labels for what you want to predict is. An example of this is activity tagging data. For each day twenty four hours of time-series data are gathered on the subject, but often when asked to tag the data they only tag specific instances of activities, leaving much of the day blank. In addition it is often infeasible to ask them to label all of their data. Another example comes from EHR based studies. Many times these studies rely on using physicians to perform chart reviews in order to construct their training and test sets. This is a costly and time consuming procedure. Figure 5.2: Visual example of how adding unlabeled data can provide valuable information about the shape of the data valuable for classification. Image taken from Wikipedia There are various approaches to approaching this issue. A very promising one is the use of an initial unsupervised learning task on the data, followed by a supervised learning step using features learned by the unsupervised step. For instance, say we wished to classify sentiment of a corpus of text, but only had labels of sentiment for a small subsection of the text. First an unsupervised model would be fit to all of the data, for instance, training the model to predict the next word in a sequence. This unsupervised model would learn to map the text at a given instance to some latent-space that most likely holds information about sentiment as well as the next word. What is then done is the final layer of the model that maps that latent-space to the next word is removed and replaced with a new layer that fits the form of our desired classification (in this case a binary outcome of “happy” or not). The model is then trained on the labeled data with the weights of the lower-layers either frozen at their values from the unsupervised step or simply initialized at them. This approach of unsupervised pre-training has been shown to yield great improvements in the performance of sequence models (Zhu (2005)). Other methods of performing semi-supervised learning include training the model on available labels, then using the trained model to classify the unlabeled data and then retraining the model treating those labels as the true values. Surprisingly this method does yield improvements over not using any unlabeled data(Zhu (2005)). Exploration of the operating characteristics of semi-supervised learning could be a valuable contribution to areas of research such as electronic health records. A pseudo power calculation could be performed at the outset of a modeling effort. This would help the researchers optimize time and money by indicating how many labeled examples needed to be collected. In addition, efforts to extend the performance benefits of semi-supervised learning could allow models to be fit to domains where they were previously not able to be due to difficulties in gathering labels for data. References "]
]
