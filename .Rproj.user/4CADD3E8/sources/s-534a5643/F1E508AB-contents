# Opportunities for advancing field {#future}

Up to now has been an overview of the techniques in deep learning that have been successfully and commonly implemented in sequential classification problems. This chapter will be devoted to new efforts of solving problems associated with the aforementioned methods. In addition to being a survey of the current state of the art it will also identify potential avenues for new research that could enhance our ability to work with sequential data subjected to various constraints. 

## What to do with all those parameters

An issue with not just sequence-based deep learning, but the field as a whole, is how large models are. For instance: VGGnet (@vggnet), the second place winner of the 2014 ImageNet competition and an extremely common model to use for image recognition tasks, has 138 million parameters to tune. Going by the rule of thumb from Frank Harrell's book "Regression Modeling Strategies" (@rms) of 10-20 observations per parameter in our model, this is an issue, especially given the size of the data-set that the VGGnet model was trained on was _only_ one million images^[This comparison is not exactly fair as images are composed of many pixels as well.]. 

Even simple neural nets have a large number of parameters. A model with just a single hidden layer taking a ten dimensional input and a hidden layer of ten neurons performing binary classification would have (with bias parameters included) $(10*11) + (10*11) + (2*11) = 242$ parameters to tune. 

### Theory backed methods for choosing model architectures

How then, did the VGGnet model achieve an accuracy of 93% on the test set? The answer lies in the fact that data is not shared over parameters in the same way it is in regression models. This stems from the fact that each layer's parameters are using as their input the output from the previous layer, and thus data are being reused. While it does not appear that this means we only need to count the parameters in the first layer, it does mean that deep learning models need to be thought of differently than traditional regression based models in terms of parameter complexity[^It also points to the advantages of deep neural nets over wide ones, a topic considered more deeply in @goodfellow_DL chapter 13.]. 

As of yet, there is no solid theoretical explanation of exactly what the data to parameter relationships are in deep neural networks, and thus there are no concrete guidelines to model construction. Difficulties in ascertaining these guidelines seems in part due to the non-convex optimization routines used for the models. 

The combination of the lack of theory and the computational time needed to perform traditional grid-search techniques for tuning layer numbers/size suggest the potential for very impactful research in this area.

### Runtime on mobile hardware

Another impact of having extremely large models is they take a long time to not only train, but to be used to predict as well. If deep learning models are to be brought to mobile devices such as smart phones or watches the models need to be scaled down in terms of their size and run time complexity substantially. Efforts towards this have been successful with models such as SqueezeNet (@squeezenet) drastically reducing the number of parameters compared to traditional convolutional networks, while still maintaining a good level of accuracy in ImageNet prediction performance. In addition, certain forms of penalization such as $L_0$ penalization can be applied to 'thin out' a network by forcing certain weights to drop to zero and then throwing them out (@sparsenets), all while performing a single run of stochastic gradient descent, eliminating the need to do costly re-training of the network after dropping weights. 

Great opportunity lies the development of objective and rigorous methods of eliminating unnecessary parameters in models. Approaches such as regularization are promising as are the evaluation of model response to techniques such as dropout (@dropout) where by neurons are randomly dropped during forward propigation in training in an effort to build robust prediction pathways. An analysis of a model's response to certain neuron's being dropped may indicate the potential for sparsity inducing techniques. 


## Inference

A great source of confusion for many statisticians when reading literature in the deep learning world is that in many cases the same words have different meanings. "Inference" is a good example of this. To a statistician inference means the dissection of the inner workings of the model: what parameters are used to make predictions and how confident are we in those parameters. In deep learning, inference typically refers to the use of a model for prediction. There are a few things that stand in the way of traditional inference in deep learning models. 


### Peering into the black box

Often it is common to hear people refer to deep neural networks as "black box predictors." This meaning simply that data goes in and the model performs some uninterpretable transformations to that data and returns its prediction. While in giant models such as VGGnet may make this seem like the case, it is actually quite possible to see what is going on within a neural network, just the quantity of information to understand is too high to fully comprehend it in its raw form. 

The desire for traditional inference in the statistical sense is a limiting goal. Having a parameter estimate and its uncertainty works well when models are single-stage linear combinations of the data, but neural networks, and arguably the world, does not usually work in linear combinations. Traditional inference has relied on making (hopefully) non-impactful simplifications of the true nature of the system being modeled in order for it to fit the framework of linear models. 

With deep learning we have a system theoretically capable of modeling any function of data and we should take advantage of that. If the model objectively performs well, we should perform the simplification on the explanation side, rather than the model side. How exactly this is done is not a solved issue (and may never be), but some early examples include the work of visualizing the intermediate layers in computer vision models (@cnn_vis): investigating the features learned by neural networks can provide great insight into the way it parsing the signals in the data. 

### Generative Adversarial Networks

One approach that allows simultaneously attempting to train a better model, but also understanding the workings of the model is a class of deep learning models called "generative adversarial networks" (or GANs)(@gans). GANs train two separate neural networks in tandem: a generator and a discriminator. The job is for the generator to construct fake examples of some training set and the discriminator's job is to decide if the example is a real observation or a generated one. These models have shown remarkable results in terms of image generation such as those recently presented by NVIDIA \@ref(fig:ganexample) (@progressive_gans).  

```{r,  out.height = 320, fig.align = "center", echo = FALSE, label = "ganexample", fig.cap = "The output of a generative adversarial network trained on a database of celebrity faces. Both faces seen are entirely generated by the model and show that it learned to a very precise degree, what constitutes a 'face.'"}
knitr::include_graphics("figures/gan_example.png")
```

The output produced by the generator model of GANs effectively show what the descriminator model is 'seeing' when it chooses to classify something as a given class. For instance, an over-fit model may classify a house as a house because it sees a lot of the color blue in the sky. If that was the case a GAN would simply return a blue canvas when asked to generate a house^[Another similar approach is neural networks with 'attention' mechanisms (@attention). These mechanisms can be used to explore what exactly in the data is contributing heavily to a given classification.]. 

Recently, a team at ETH Zurich used GANs on time series data taken from hospital records (@medical_gans) and found that GANs could be used successfully on these data to generate realistic looking medical data, suggesting that the model was learning underlying patterns well^[This opens a fascinating ethical conundrum in that, theoretically if over-fit, the model could serve to simple memorize patient data and would be a serious privacy threat. How do we decide when the model is interpreting general trends and when it's working on the individual level? Are there cases for both?]. 


### Causality problems

While much of deep learning is not currently focused on uncovering causal pathways^[It is being explored however, particularly in the Bayesian deep learning communities.], given the ability of these models to generalize so well, it is worth exploring the issue more. One area of concern with the models mentioned is the temporal order of data. For instance, in convolutional methods for sequence classification, often the convolutions are allowed to explore not only back in time, but also forward in time to classify at a given instance. The same goes with a class of RNNs that we didn't discuss but have proved successful: the bi-directional RNN. In this case the RNN's hidden state path travels not only forward in time, but also backwards. 

These models that can see both backward and forward in time often perform better than their omni-directional counterparts. For instance, in speech the "au" phoneme may indicate an 'e' or an 'a' in a word, but it only becomes clear after the end of the word is heard which value it is. However, the flow of causality is forward in time, so these models explicitly violate this. 

Potentially fitting a model that has the ability to see both forward and reverse temporal dependencies and then investigating the dependencies that were discovered by both directions could provide some insight into this. For instance, if the backwards in time component of the RNN found that the administration of some drug was a strong signal that high blood-pressure would later occur, but not the reverse direction the relationship could warrant further experimental exploration of causality potential. 
It would be necessary to make sure that the patterns discovered were not due to residuals from the reverse-time predictors, but this could be done by forcing the model to 'forget' those patterns and seeing if our forward-time trends remain.


## Small or sparse data

Deep learning has come to be almost synonymous with 'big data.' Most of the groundbreaking work tends to come out of large companies with massive data-sets and near-infinite compute power to fit their models. This has left the area of deep learning corresponding to small data relatively unexplored. We have already seen that deep learning models seem to use their parameters more efficiently than traditional statistical methods, but that is clearly not without limit. The following are a brief survey of a few techniques for dealing with small or sparse (meaning a large portion missing labels) data. 

### Bayesian deep learning

As we have seen, a neural network is essentially a series of stacked linear models with static non-linear transformations applied. Much like we can fit a regression model in a Bayesian context, we can fit a deep neural network with Bayesian techniques. To do so, each tuneable parameter is simply provided a prior (usually a normal centered at zero) distribution and the posterior distribution is determined the same as any other Bayesian model. Usually variational inference techniques are used instead of sampling techniques such as Hamiltonian Monte Carlo due to the size of the models (@bayesnets). 

Bayesian neural networks have been shown to perform more efficiently on small data-sets than traditional models (@dropout). In addition, some generative models such as autoencoders (see section below) have shown subjectively better results from Bayesian implementations than standard implementations (@variational_autoencoders). 


### Semi-supervised methods

In many circumstances the data may not be small as a whole, but the number of observations that have labels for the desired prediction are. An example of this is activity tagging data. For each day twenty four hours of time-series data are gathered on the subject, but often when asked to tag the data they only tag specific instances of activities, leaving much of the day blank. In addition it is often infeasible to ask them to label every day of their data. 

Another example comes from EHR based studies. Many times these studies rely on using physicians to perform chart reviews in order to construct their training and test sets. This is a costly and time consuming procedure. 

```{r,  out.height = 320, fig.align = "center", echo = FALSE, label = "semisupervised", fig.cap = "Visual example of how adding unlabeled data can provide valuable information about the shape of the data valuable for classification. Image taken from [Wikipedia](https://en.wikipedia.org/wiki/Semi-supervised_learning)"}
knitr::include_graphics("figures/semi-supervised.png")
```



There are various approaches to dealing with this sparse data issue. A very promising avenue is the preliminary fitting of an unsupervised model on the data, followed by a supervised learning model using features learned by the unsupervised model 

Say we wished to classify sentiment of a corpus of text, but only had labels of sentiment for a small subsection of the text. First an unsupervised model would be fit to all of the data. For instance a model trained to predict the next word in a sentence. This unsupervised model would learn to map the text at a given time-point to some latent-space that holds information about the next word and most likely sentiment as well. Tthe final layer of the word prediction model that maps that latent-space to the next word is removed and replaced with a new layer that fits the form of our desired classification (in this case a binary outcome of "happy" or not). This new model is then trained on the labeled data with the weights of the lower-layers either frozen at their values from the unsupervised step or simply initialized at them. 

This approach of unsupervised pre-training has been shown to yield great improvements in the performance of sequence models (@semi_supervised). 

Other methods of performing semi-supervised learning include training the model on available labels, then using the trained model to classify the unlabeled data and then retraining the model treating those labels as the true values. Surprisingly this method does almost always yield improvements over not using any unlabeled data(@semi_supervised). 

Exploration of the operating characteristics of semi-supervised learning scenarios could be a valuable contribution to areas of research such as electronic health records. An example of potential impact: a pseudo power calculation could be performed at the outset of a modeling effort. This would help the researchers optimize time and money by informing how many labeled examples needed to be collected. In addition, efforts to extend the performance benefits of semi-supervised learning could allow models to be fit to domains where they were previously not able to be due to difficulties in gathering labels for data. 

 